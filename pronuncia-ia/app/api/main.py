try:
    from fastapi import FastAPI, UploadFile, Form, Request, File
    from fastapi.responses import JSONResponse
except Exception as e:
    raise RuntimeError(
        "Depend√™ncia ausente: instale FastAPI e Uvicorn (por exemplo: `pip install fastapi uvicorn`) antes de executar este m√≥dulo."
    ) from e

from app.api.schemas import EvaluateResponse, TranscribeResponse
from pydantic import BaseModel
from typing import Optional
import os 
import sys 
import pathlib
import tempfile
import uuid
import base64
from pathlib import Path

# Carregar vari√°veis de ambiente o mais cedo poss√≠vel
try:
    from dotenv import load_dotenv
    # Tenta m√∫ltiplos caminhos para .env para suportar execu√ß√µes diferentes
    possible_envs = [
        Path(__file__).parent.parent.parent / ".env",        # pronuncia-ia/.env
        Path(__file__).resolve().parents[3] / ".env",         # repo root .env (c317---IA/.env)
        Path.cwd() / ".env",                                  # cwd/.env
    ]
    _env_loaded = None
    for p in possible_envs:
        try:
            if p.exists():
                load_dotenv(dotenv_path=p)
                _env_loaded = p
                break
        except Exception:
            continue
    if _env_loaded:
        print(f"[DEBUG] main.py: .env carregado de {_env_loaded}")
    else:
        print(f"[DEBUG] main.py: nenhum .env encontrado em {[str(p) for p in possible_envs]}")
except Exception as _e:
    print(f"[DEBUG] main.py: falha ao carregar .env antecipadamente: {_e}")

# Add the parent directory (or its parent) to sys.path to resolve 'scoring' import
core_path = pathlib.Path(__file__).parent.parent / "core"
sys.path.insert(0, str(core_path))

from app.core.scoring import pronunciation_score, pronunciation_score_with_ai

# Importa√ß√£o dos modelos de transcri√ß√£o e IA
models_path = pathlib.Path(__file__).parent.parent.parent / "models"
sys.path.insert(0, str(models_path))

# Modelos dispon√≠veis (alguns comentados por escolha de arquitetura):
try:
    from app.models.modelos import (
    Whisper,              # Usado: transcri√ß√£o local
    # Wav2Vec2,           # Testado: bom para portugu√™s, mas focado em transcri√ß√£o
    # DeepSpeech,         # Testado: leve mas limitado em idiomas
    # CoquiSTT,           # Testado: open source mas requer muito fine-tuning
    # FasterWhisper,      # Testado: mais r√°pido mas sem vantagem para nosso caso
    OpenAITranscriber,    # Usado: transcri√ß√£o via API
    GeminiTranscriber,    # Usado: transcri√ß√£o via API
    OpenAIChat,           # Usado: avalia√ß√£o qualitativa com GPT
        GeminiChat            # Usado: avalia√ß√£o qualitativa com Gemini
    )
except Exception:
    # Durante desenvolvimento local o pacote pode n√£o estar resolvido via package imports.
    # Fallback para import via path inserido anteriormente.
    # If fallback fails, raise so the error surfaces during startup rather than silently failing later
    from modelos import (
        Whisper,
        OpenAITranscriber,
        GeminiTranscriber,
        OpenAIChat,
        GeminiChat,
    )

app = FastAPI(
    title="API de Avalia√ß√£o de Pron√∫ncia com IA",
    description="Sistema inteligente que usa GPT/Gemini para avaliar pron√∫ncia de forma qualitativa",
    version="2.0.0"
)


@app.get("/debug_env")
async def debug_env():
    """Endpoint tempor√°rio para verificar se as chaves de API est√£o vis√≠veis no processo.

    Retorna booleans e um valor mascarado (primeiros 6 chars) para ajudar debug sem expor a chave inteira.
    """
    def mask(v: str | None) -> str | None:
        if not v:
            return None
        return v[:6] + "..." if len(v) > 6 else "***"

    gem = os.getenv("GEMINI_API_KEY")
    goo = os.getenv("GOOGLE_API_KEY")
    return JSONResponse({
        "GEMINI_present": bool(gem),
        "GOOGLE_present": bool(goo),
        "GEMINI_masked": mask(gem),
        "GOOGLE_masked": mask(goo),
        "python_executable": sys.executable,
    })
# Modelo principal de transcri√ß√£o (local, gr√°tis, razoavelmente preciso)
# DESABILITADO: Whisper local consome muita RAM
# whisper_model = Whisper(device='cpu')  # Use 'cuda' se tiver GPU
whisper_model = None  # Usar apenas Gemini (sem Whisper local)

# ============================================================================
# NOTA SOBRE ESCOLHA DE MODELOS:
# ============================================================================
# Testamos diversos modelos STT durante o desenvolvimento:
#
# 1. Whisper (OpenAI) - ESCOLHIDO para transcri√ß√£o local
#    ‚úÖ Multil√≠ngue, boa precis√£o, uso offline
#    ‚ùå Mais lento que alternativas especializadas
#
# 2. Wav2Vec2 - Testado mas n√£o implementado como padr√£o
#    ‚úÖ Excelente para portugu√™s brasileiro
#    ‚ùå Requer fine-tuning por idioma, complexidade adicional
#
# 3. FasterWhisper - Testado mas n√£o necess√°rio
#    ‚úÖ 4x mais r√°pido que Whisper
#    ‚ùå Sem ganho significativo para nosso caso de uso
#
# 4. DeepSpeech / Coqui STT - Testados mas descartados
#    ‚úÖ Leves e r√°pidos
#    ‚ùå Modelos pr√©-treinados limitados, requerem treino personalizado
#
# Para AVALIA√á√ÉO, optamos por LLMs (GPT/Gemini) ao inv√©s de:
# - Algoritmos de similaridade fon√©tica (limitados)
# - An√°lise de MFCCs e features ac√∫sticas (complexo)
# - Modelos especializados em pron√∫ncia (poucos dispon√≠veis)
#
# Raz√£o: LLMs oferecem feedback pedag√≥gico superior
# ============================================================================


# Fun√ß√£o dummy para simular caminho de √°udio (j√° que n√£o h√° upload de arquivo)
def _get_audio_path(audio_dict):
    # Aqui voc√™ pode implementar l√≥gica para buscar o arquivo pelo nome, se necess√°rio
    # Por enquanto, s√≥ retorna o nome
    return audio_dict.get("name", "")

def _normalizar_provedor(provedor: str) -> str:
    return (provedor or "gemini").lower()  # MUDADO: gemini como padr√£o

def _transcrever_arquivo(caminho_tmp: str, provedor: str) -> str:
    prov = _normalizar_provedor(provedor)
    # Mock provider for local testing without API keys
    if prov == "mock":
        # Return a stable expected transcription for tests
        return "o rato roeu a roupa do rei de roma"
    if prov == "openai":
        return OpenAITranscriber().transcribe(caminho_tmp)
    if prov == "gemini":
        return GeminiTranscriber().transcribe(caminho_tmp)
    # Whisper local desabilitado (falta de RAM)
    # return whisper_model.transcribe(caminho_tmp)
    # Se pedir whisper, usar gemini
    return GeminiTranscriber().transcribe(caminho_tmp)


# Fun√ß√£o para processar upload de arquivo e transcrever
async def _transcrever_upload(audio: UploadFile, provedor: str) -> str:
    data = await audio.read()
    suffix = os.path.splitext(audio.filename or "")[1] or ".wav"
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
        tmp.write(data)
        tmp_path = tmp.name
    try:
        return _transcrever_arquivo(tmp_path, provedor)
    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass


# _transcrever_upload n√£o √© mais usado pelo endpoint /avaliar (JSON)


def _resposta_chat_texto(texto: str, provedor: str, sistema: str) -> str:
    prov = _normalizar_provedor(provedor)
    if prov == "gemini":
        return GeminiChat().reply_from_text(texto, system=sistema)
    if prov == "openai":
        return OpenAIChat().reply_from_text(texto, system=sistema)
    raise RuntimeError("Provider sem chat: use 'openai' ou 'gemini'.")
@app.post("/avaliar")
async def avaliar(
    request: Request,
    user_id: Optional[str] = Form(None),
    action: str = Form("evaluate"),  # transcribe | evaluate | chat
    target_word: Optional[str] = Form(None),
    audio: Optional[UploadFile] = File(None),
    ai_scoring: bool = Form(True),
    provider: str = Form("gemini"),
    scoring_provider: str = Form("gemini"),
    threshold: Optional[float] = Form(None),
    language: str = Form("portugu√™s"),
    system: str = Form("Voc√™ √© um assistente √∫til que responde de forma curta."),
):
    provider = (provider or "gemini").lower()
    scoring_provider = (scoring_provider or "gemini").lower()
    action = (action or "evaluate").lower()
    """
    üéØ Endpoint PRINCIPAL para avaliar a pron√∫ncia com IA.
    
    **Fluxo:**
    1. Transcreve o √°udio (Whisper local OU OpenAI/Gemini)
    2. Avalia com GPT/Gemini (feedback qualitativa detalhado)
    
    **Par√¢metros:**
    - user_id: ID do usu√°rio
    - target_word: Palavra/frase que deveria ser falada
    - audio: Arquivo de √°udio (.wav, .mp3, .opus, etc)
    - provider: Modelo para transcri√ß√£o (whisper=local, openai, gemini)
    - ai_scoring: Se True, usa IA para avaliar (recomendado!)
    - scoring_provider: Qual IA usar na avalia√ß√£o (openai ou gemini)
    - language: Idioma para contextualizar feedback
    
    **Retorno:**
    - score: Nota de 0 a 100
    - feedback: An√°lise detalhada da pron√∫ncia
    - suggestions: Dicas para melhorar
    - errors: Lista de erros espec√≠ficos
    - highlights: O que acertou/errou
    """
    # Prepare audio file: accept multipart upload OR JSON with base64
    tmp_created = False
    audio_path = None
    # If multipart/form-data provided file
    if audio is not None:
        data = await audio.read()
        suffix = os.path.splitext(audio.filename or "")[1] or ".wav"
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(data)
            audio_path = tmp.name
        tmp_created = True
    else:
        # try to parse JSON body for base64 audio
        content_type = request.headers.get("content-type", "")
        if "application/json" in content_type:
            try:
                j = await request.json()
            except Exception:
                return JSONResponse({"error": "Corpo JSON inv√°lido."}, status_code=400)

            # map fields if present in JSON
            user_id = user_id or j.get("user_id")
            action = j.get("action", action)
            target_word = target_word or j.get("target_word")
            ai_scoring = ai_scoring if ("ai_scoring" not in j) else (str(j.get("ai_scoring")).lower() in ["true", "1"])
            provider = j.get("provider", provider)
            scoring_provider = j.get("scoring_provider", scoring_provider)
            threshold = j.get("threshold", threshold)
            language = j.get("language", language)
            system = j.get("system", system)

            audio_b64 = None
            audio_name = "audio.wav"
            if isinstance(j.get("audio"), dict) and j["audio"].get("base64"):
                audio_b64 = j["audio"].get("base64")
                audio_name = j["audio"].get("name", audio_name)
            elif j.get("audio_base64"):
                audio_b64 = j.get("audio_base64")
                audio_name = j.get("audio_name", audio_name)

            if audio_b64:
                try:
                    decoded = base64.b64decode(audio_b64)
                except Exception:
                    return JSONResponse({"error": "Campo audio_base64 inv√°lido (n√£o √© base64)."}, status_code=400)

                suffix = os.path.splitext(audio_name)[1] or ".wav"
                fd, path = tempfile.mkstemp(suffix=suffix)
                with os.fdopen(fd, "wb") as f:
                    f.write(decoded)
                audio_path = path
                tmp_created = True

    if not audio_path:
        return JSONResponse({"detail": [{"type": "missing", "loc": ["body", "user_id"], "msg": "Field required", "input": None}, {"type": "missing", "loc": ["body", "audio"], "msg": "Field required", "input": None}]}, status_code=400)

    try:
        # Usa o arquivo salvo para transcri√ß√£o (Gemini espera caminho de arquivo real)
        transcription = _transcrever_arquivo(audio_path, provider)
    except Exception as e:
        try:
            if tmp_created and audio_path and os.path.exists(audio_path):
                os.remove(audio_path)
        except Exception:
            pass
        return JSONResponse({"error": f"Falha na transcri√ß√£o ({provider}): {e}"}, status_code=400)

    submission_id = "sub_" + uuid.uuid4().hex

    # ACTION: transcribe -> only transcription
    if action == "transcribe":
        try:
            return JSONResponse({
                "submission_id": submission_id,
                "transcription": transcription,
                "status": "done",
                "provider": provider,
            })
        finally:
            try:
                os.remove(audio_path)
            except Exception:
                pass

    # ACTION: chat -> transcribe + chat reply
    if action == "chat":
        try:
            try:
                reply = _resposta_chat_texto(transcription, provider, system)
            except Exception as e:
                return JSONResponse({"error": f"Falha ao conversar com {provider}: {e}"}, status_code=400)

            return JSONResponse({
                "submission_id": submission_id,
                "transcription": transcription,
                "reply": reply,
                "provider": provider,
            })
        finally:
            try:
                os.remove(audio_path)
            except Exception:
                pass

    # ACTION: evaluate (default) -> transcribe + scoring
    try:
        if ai_scoring:
            score_result = pronunciation_score_with_ai(
                target_word,
                transcription,
                provider=scoring_provider,
                language=language,
            )
        else:
            score_result = pronunciation_score(target_word, transcription)
    finally:
        try:
            os.remove(audio_path)
        except Exception:
            pass

    # enrich result with common fields
    score_result["user_id"] = user_id
    score_result["transcription_provider"] = provider
    score_result["audio_name"] = audio.filename
    score_result["submission_id"] = submission_id
    score_result["transcription"] = transcription

    # compute pass if threshold provided and numeric score is present
    try:
        if threshold is not None and isinstance(score_result.get("score"), (int, float)):
            score_result["pass"] = float(score_result.get("score")) >= float(threshold)
    except Exception:
        pass

    # Garantir que o campo `match` exista (compatibilidade com m√©todo tradicional)
    if "match" not in score_result:
        score_result["match"] = bool(score_result.get("hit", False))

    return JSONResponse(score_result)

@app.post("/falar")
async def falar(
    audio: UploadFile = Form(...),
    provider: str = Form("openai"),  # openai | gemini
    system: str = Form("Voc√™ √© um assistente √∫til que responde de forma curta."),
):
    """
    Fala com o modelo via √°udio: transcreve e envia ao LLM selecionado.
    Retorna { transcript, reply }.
    """
    try:
        transcript = await _transcrever_upload(audio, provider)
    except Exception as e:
        return JSONResponse({"error": f"Falha na transcri√ß√£o ({provider}): {e}"}, status_code=400)

    try:
        reply = _resposta_chat_texto(transcript, provider, system)
    except Exception as e:
        return JSONResponse({"error": f"Falha ao conversar com {provider}: {e}"}, status_code=400)

    return JSONResponse({"transcript": transcript, "reply": reply})

@app.post("/transcrever")
async def transcrever(
    audio: UploadFile = Form(...),
    provider: str = Form("whisper"),  # whisper | openai | gemini
):
    """
    Teste simples: retorna apenas a transcri√ß√£o do √°udio.
    """
    try:
        transcript = await _transcrever_upload(audio, provider)
        return JSONResponse({"transcript": transcript})
    except Exception as e:
        return JSONResponse({"error": f"Falha na transcri√ß√£o ({provider}): {e}"}, status_code=400)

@app.post("/chat_texto")
async def chat_texto(
    message: str = Form(...),
    provider: str = Form("openai"),  # openai | gemini
    system: str = Form("Voc√™ √© um assistente √∫til que responde de forma curta."),
):
    """
    Teste simples: conversa via texto com o LLM (sem √°udio).
    """
    try:
        reply = _resposta_chat_texto(message, provider, system)
        return JSONResponse({"reply": reply})
    except Exception as e:
        return JSONResponse({"error": f"Falha ao conversar com {provider}: {e}"}, status_code=400)

@app.post("/tutor_pronuncia")
async def tutor_pronuncia(
    message: str = Form(...),
    provider: str = Form("openai"),  # openai | gemini
):
    """
    üéì NOVO: Tutor de pron√∫ncia interativo via texto.
    
    Conversa natural sobre pron√∫ncia, d√∫vidas, dicas, exerc√≠cios.
    Exemplo: "Como pronunciar 'through'?" ou "Tenho dificuldade com R em ingl√™s"
    """
    system_prompt = """Voc√™ √© um professor de pron√∫ncia especializado e paciente.

SEU PAPEL:
- Ajudar alunos a melhorar pron√∫ncia em qualquer idioma
- Explicar sons dif√≠ceis de forma clara e pr√°tica
- Dar exerc√≠cios e dicas personalizadas
- Ser encorajador e motivador

ESTILO:
- Use emojis para tornar mais amig√°vel üéØ
- D√™ exemplos pr√°ticos e compara√ß√µes
- Se o aluno perguntar sobre uma palavra espec√≠fica, explique cada som
- Sugira exerc√≠cios quando apropriado

FORMATO:
- Seja conciso mas completo
- Use bullets quando listar dicas
- Destaque sons problem√°ticos com **negrito**"""

    try:
        reply = _resposta_chat_texto(message, provider, system_prompt)
        return JSONResponse({
            "reply": reply,
            "provider": provider,
            "mode": "tutor"
        })
    except Exception as e:
        return JSONResponse({"error": f"Falha ao conversar com tutor: {e}"}, status_code=400)

# -----------------------
# Cat√°logo de tarefas e gerador simples
# -----------------------
tasks_catalog = {
    "leitura_rapida": {
        "title": "Leitura R√°pida / Flu√™ncia Verbal",
        "description": "Textos curtos (10‚Äì15 segundos) para avaliar velocidade, pros√≥dia e clareza.",
        "expected_duration_s": 12,
        "instructions": "Leia o texto em voz alta de forma natural, sem pausas longas.",
        "samples": [
            "O rato roeu a roupa do rei de Roma.",
            "O sol nasceu e a cidade acordou.",
            "Hoje a escola ter√° aula de m√∫sica e pintura."
        ],
        "suggested_threshold": 65
    },
    "trava_linguas": {
        "title": "Trava-l√≠nguas",
        "description": "Frases com alta complexidade articulat√≥ria; repeti√ß√£o r√°pida e precisa.",
        "expected_duration_s": 8,
        "instructions": "Repita o trava-l√≠nguas rapidamente mantendo clareza articulat√≥ria.",
        "samples": [
            "Tr√™s pratos de trigo para tr√™s tigres tristes",
            "O rato roeu a roupa do rei de Roma",
            "P√£o com massa, passa a massa no pano"
        ],
        "suggested_threshold": 70
    },
    "frases_curtas": {
        "title": "Frases Curtas de Repeti√ß√£o / Leitura",
        "description": "Frases simples para avaliar mem√≥ria auditiva e organiza√ß√£o sint√°tica.",
        "expected_duration_s": 5,
        "instructions": "Repita cada frase exatamente como ouvido ou leia em voz alta.",
        "samples": [
            "Ela abriu a janela.", "O menino comprou p√£o.", "Passa o sal, por favor."
        ],
        "suggested_threshold": 60
    },
    "repeticao_fonemas": {
        "title": "Repeti√ß√£o de Fonemas e Pares M√≠nimos",
        "description": "Contraste de fonemas e pares m√≠nimos para discrimina√ß√£o e articula√ß√£o.",
        "expected_duration_s": 6,
        "instructions": "Repita cada par claramente, com espa√ßo entre as palavras.",
        "samples": [
            "papa / baba", "pato / bato", "sapo / xapo", "casa / ca√ßa"
        ],
        "suggested_threshold": 70
    },
    "leitura_palavras": {
        "title": "Leitura de Palavras e Pseudopalavras",
        "description": "Listas misturando palavras reais e pseudopalavras.",
        "expected_duration_s": 8,
        "instructions": "Leia a lista de palavras em voz alta, tentando manter ritmo constante.",
        "samples": [
            "gato, casa, pind√≥, maral, tromba", "festa, bico, lapor, suven"
        ],
        "suggested_threshold": 65
    },
    "repeticao_silabas": {
        "title": "Repeti√ß√£o de S√≠labas",
        "description": "Sequ√™ncias sil√°bicas organizadas para controle articulat√≥rio e coordena√ß√£o.",
        "expected_duration_s": 6,
        "instructions": "Repita a sequ√™ncia rapidamente e de forma cont√≠nua.",
        "samples": [
            "pa pe pi po pu", "tr√™s tigres tristes", "pinga a pipoca na panela"
        ],
        "suggested_threshold": 60
    },
    "trava_linguas_progressiva": {
        "title": "Trava-l√≠nguas com Progress√£o Sil√°bica",
        "description": "Combina s√≠labas repetitivas e frases dif√≠ceis com progress√£o de dificuldade.",
        "expected_duration_s": 10,
        "instructions": "Execute a progress√£o come√ßando devagar e aumentando a velocidade mantendo clareza.",
        "samples": [
            "pa pe pi po pu - pa pe pi po pu - pa pe pi po pu",
            "tr√™s tigres tristes tricotando tr√™s tric√¥s"
        ],
        "suggested_threshold": 72
    }
}

def _extract_target_words(text: str, category: str):
	"""Heur√≠stica simples para extrair poss√≠veis alvo(s) de cada item."""
	import re
	category = (category or "").lower()
	if category == "repeticao_fonemas":
		# pares separados por /
		if "/" in text:
			parts = [p.strip() for p in text.split("/")]
			return parts
		return [w.strip() for w in re.split(r"[,\s]+", text) if w.strip()]
	if category == "leitura_palavras":
		# palavras separadas por v√≠rgula
		return [w.strip() for w in text.split(",") if w.strip()]
	if category == "repeticao_silabas":
		# retorna s√≠labas/words
		return [w.strip() for w in re.split(r"[,\s]+", text) if w.strip()]
	if category == "frases_curtas" or category == "leitura_rapida":
		# escolher palavras-chaves (substantivos/verbos) - heur√≠stica: words >3 chars
		words = [w.strip(".,") for w in text.split() if len(w.strip(".,") ) > 3]
		return words[:3] if words else [text]
	return [text]

def _generate_texts(category: str, count: int = 5, age_group: str = "adulto", difficulty: str = "medio", include_meta: bool = False):
    """
    Gerador simples sem IA para criar varia√ß√µes de itens por categoria.
    - agora suportando include_meta: quando True, retorna dicts com meta √∫teis.
    """
    import random
    if category not in tasks_catalog:
        raise ValueError("Categoria desconhecida")

    samples = tasks_catalog[category]["samples"]
    out = []

    # par√¢metros simples para ajuste de comprimento e complexidade
    word_multiplier = 1
    if age_group == "infantil":
        word_multiplier = 1
    elif age_group == "juvenil":
        word_multiplier = 1.3
    else:
        word_multiplier = 1.6

    if difficulty == "facil":
        word_multiplier *= 0.9
    elif difficulty == "dificil":
        word_multiplier *= 1.2

    # Gera√ß√£o por categoria (regras simples)
    for i in range(count):
        item_text = ""
        if category == "leitura_rapida":
            parts = [random.choice(samples) for _ in range(max(1, int(word_multiplier)))]
            item_text = " ".join(parts)
        elif category == "repeticao_fonemas":
            p = random.choice(samples)
            if random.random() < 0.5:
                item_text = p
            else:
                a, b = p.split("/") if "/" in p else (p, p)
                item_text = f"{a.strip()} / {b.strip()}"
        elif category == "leitura_palavras":
            words = []
            for _ in range(max(4, int(4 * word_multiplier))):
                w = random.choice(random.choice(samples).split(","))
                words.append(w.strip())
            item_text = ", ".join(words)
        elif category == "frases_curtas":
            base = random.choice(samples)
            if random.random() < 0.5:
                item_text = base
            else:
                item_text = base + " " + random.choice(["Ela sorriu.", "Ele caminhou.", "O vento soprou."])
        elif category == "repeticao_silabas":
            if random.random() < 0.6:
                item_text = " ".join([random.choice(samples).split()[0] for _ in range(max(3, int(3 * word_multiplier)))])
            else:
                item_text = random.choice(samples)
        else:
            item_text = random.choice(samples)

        if include_meta:
            meta = {
                "text": item_text,
                "target_words": _extract_target_words(item_text, category),
                "instructions": tasks_catalog[category].get("instructions", ""),
                "estimated_duration_s": tasks_catalog[category].get("expected_duration_s", None)
            }
            out.append(meta)
        else:
            out.append(item_text)

    # garante unicidade simples
    seen = set()
    unique_out = []
    for t in out:
        # t pode ser dict ou str
        key = t["text"] if isinstance(t, dict) else t
        if key not in seen:
            unique_out.append(t)
            seen.add(key)
    return unique_out

# -----------------------
# Novos endpoints: listar e gerar tarefas
# -----------------------
@app.get("/tarefas")
async def listar_tarefas():
    """Retorna as categorias de tarefas e metadados (nome, descri√ß√£o, n√∫mero de exemplos)."""
    result = {
        k: {
            "title": v["title"],
            "description": v["description"],
            "sample_count": len(v.get("samples", []))
        }
        for k, v in tasks_catalog.items()
    }
    return JSONResponse(result)

@app.post("/tarefas/gerar")
async def gerar_tarefas(
    category: str = Form(...),                # chave da categoria (ex: leitura_rapida)
    count: int = Form(5),                     # quantos itens gerar
    age_group: str = Form("adulto"),          # infantil | juvenil | adulto
    difficulty: str = Form("medio"),          # facil | medio | dificil
    include_meta: bool = Form(False)          # se true, retorna objetos com meta (target_words, instructions...)
):
    """Gera N textos/itens para a categoria solicitada (sem uso de IA)."""
    category = (category or "").strip().lower()
    if category not in tasks_catalog:
        return JSONResponse({"error": "Categoria desconhecida", "available": list(tasks_catalog.keys())}, status_code=400)
    try:
        texts = _generate_texts(category, count=count, age_group=age_group, difficulty=difficulty, include_meta=include_meta)
        return JSONResponse({
            "category": category,
            "title": tasks_catalog[category]["title"],
            "age_group": age_group,
            "difficulty": difficulty,
            "items": texts
        })
    except Exception as e:
        return JSONResponse({"error": f"Falha ao gerar tarefas: {e}"}, status_code=500)

@app.get("/")
async def root():
    """P√°gina inicial da API com documenta√ß√£o"""
    return {
        "message": "üéØ API de Avalia√ß√£o de Pron√∫ncia com IA",
        "version": "2.0.0",
        "endpoints": {
            "/avaliar": "Avaliar pron√∫ncia com feedback de IA (POST)",
            "/falar": "Conversar via √°udio com IA (POST)",
            "/transcrever": "Apenas transcrever √°udio (POST)",
            "/chat_texto": "Chat via texto (POST)",
            "/tutor_pronuncia": "Tutor interativo de pron√∫ncia (POST)",
            "/docs": "Documenta√ß√£o interativa Swagger"
        },
        "providers": {
            "transcription": ["whisper", "openai", "gemini"],
            "scoring": ["openai", "gemini"],
            "chat": ["openai", "gemini"]
        },
        "features": [
            "‚úÖ Transcri√ß√£o de √°udio com m√∫ltiplos modelos",
            "‚úÖ Avalia√ß√£o qualitativa com GPT/Gemini",
            "‚úÖ Feedback detalhado e personalizado",
            "‚úÖ Sugest√µes de melhoria",
            "‚úÖ Tutor de pron√∫ncia interativo",
            "‚úÖ Chat por √°udio ou texto"
            ]
        }